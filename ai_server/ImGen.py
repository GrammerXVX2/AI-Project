import uvicorn
import asyncio
import json
import psutil
import pynvml
import base64
import io
from pathlib import Path
from typing import Optional
from datetime import datetime
from fastapi import FastAPI, HTTPException, WebSocket
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from llama_cpp import Llama
import torch
import numpy as np
from PIL import Image
from transformers import pipeline
import warnings
warnings.filterwarnings('ignore')

# ==========================================
# 1. –ù–ê–°–¢–†–û–ô–ö–ò –ò –ü–£–¢–ò
# ==========================================
BASE_DIR = Path(__file__).resolve().parent
MODELS_DIR = BASE_DIR / "models"

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–∞–º—è—Ç–∏ –¥–ª—è RTX 3050 (4GB VRAM) + R7 6800H (16GB RAM)
GPU_MEMORY_MB = 3800  # –û—Å—Ç–∞–≤–ª—è–µ–º 200MB –∑–∞–ø–∞—Å–∞
RAM_MEMORY_MB = 12000  # –û—Å—Ç–∞–≤–ª—è–µ–º 4GB –¥–ª—è –û–°

# –ú–æ–¥–µ–ª–∏
QWEN_MODEL_PATH = MODELS_DIR / "Qwen3-4B-UD-Q5_K_XL.gguf"
TURBO_MODEL_PATH = MODELS_DIR / "z_image_turbo-Q8_0.gguf"

# ==========================================
# 2. –ö–õ–ê–°–°–´ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò
# ==========================================
class GenerationParams(BaseModel):
    prompt: str
    model: str = "turbo"  # "turbo" –∏–ª–∏ "qwen"
    num_inference_steps: int = 20
    guidance_scale: float = 7.5
    temperature: float = 0.7
    seed: Optional[int] = None
    width: int = 512
    height: int = 512
    batch_size: int = 1

class SystemStats(BaseModel):
    gpu_memory_free_mb: int
    gpu_memory_used_mb: int
    gpu_memory_total_mb: int
    ram_free_mb: int
    ram_used_mb: int
    ram_total_mb: int
    gpu_utilization: float

# ==========================================
# 3. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –°–ò–°–¢–ï–ú
# ==========================================
print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ImGen —Å–µ—Ä–≤–µ—Ä–∞...")
print(f"üìÅ –ö–∞—Ç–∞–ª–æ–≥ –º–æ–¥–µ–ª–µ–π: {MODELS_DIR}")

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(title="ImGen - Image Generation Server", version="1.0.0")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# NVIDIA GPU –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
try:
    pynvml.nvmlInit()
    GPU_AVAILABLE = True
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"‚úÖ GPU –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.cuda.get_device_name(0)}")
except Exception as e:
    GPU_AVAILABLE = False
    DEVICE = torch.device("cpu")
    print(f"‚ö†Ô∏è GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

# ==========================================
# 4. –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô (–° –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ï–ô –ü–ê–ú–Ø–¢–ò)
# ==========================================

class ModelManager:
    def __init__(self):
        self.qwen_model = None
        self.turbo_model = None
        self.current_model = None
        self.load_status = {}
        
    def load_qwen_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç Qwen3-4B —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è GPU"""
        try:
            print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ Qwen3-4B –º–æ–¥–µ–ª–∏...")
            self.qwen_model = Llama(
                model_path=str(QWEN_MODEL_PATH),
                n_ctx=2048,
                n_gpu_layers=50,  # –ú–∞–∫—Å–∏–º—É–º —Å–ª–æ–µ–≤ –Ω–∞ GPU
                n_threads=8,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º 8 CPU –ø–æ—Ç–æ–∫–æ–≤
                verbose=False,
                n_batch=256,  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
            )
            self.load_status["qwen"] = "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ (–¢–µ–∫—Å—Ç)"
            print("‚úÖ Qwen3-4B —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
        except Exception as e:
            self.load_status["qwen"] = f"‚ùå –û—à–∏–±–∫–∞: {str(e)[:50]}"
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Qwen: {e}")
            return False
    
    def load_turbo_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç Stable Diffusion –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è RTX 3050"""
        try:
            print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ Stable Diffusion v1.5 –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–µ–≥–∫—É—é Stable Diffusion v1.5 - –æ—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ RTX 3050
            from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler
            
            model_id = "runwayml/stable-diffusion-v1-5"
            
            self.turbo_model = StableDiffusionPipeline.from_pretrained(
                model_id,
                torch_dtype=torch.float16 if GPU_AVAILABLE else torch.float32,
                safety_checker=None,  # –û—Ç–∫–ª—é—á–∞–µ–º –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
                requires_safety_checker=False
            )
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—ã–π scheduler
            self.turbo_model.scheduler = EulerAncestralDiscreteScheduler.from_config(
                self.turbo_model.scheduler.config
            )
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è –º–∞–ª–æ–π –ø–∞–º—è—Ç–∏
            if GPU_AVAILABLE:
                self.turbo_model.enable_attention_slicing()
                self.turbo_model.enable_vae_slicing()
                # –î–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
                try:
                    self.turbo_model.enable_sequential_cpu_offload()
                except:
                    pass
            
            if GPU_AVAILABLE:
                self.turbo_model = self.turbo_model.to("cuda")
            
            self.load_status["turbo"] = "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ (Stable Diffusion v1.5)"
            print("‚úÖ Stable Diffusion v1.5 —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return True
        except Exception as e:
            self.load_status["turbo"] = f"‚ùå –û—à–∏–±–∫–∞: {str(e)[:50]}"
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ SD v1.5: {e}")
            return False
    
    def get_model(self, model_name: str):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
        if model_name == "qwen":
            if not self.qwen_model:
                self.load_qwen_model()
            return self.qwen_model
        elif model_name == "turbo":
            if not self.turbo_model:
                self.load_turbo_model()
            return self.turbo_model
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {model_name}")
    
    def unload_model(self, model_name: str):
        """–í—ã–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ –ø–∞–º—è—Ç–∏"""
        if model_name == "qwen" and self.qwen_model:
            del self.qwen_model
            self.qwen_model = None
            self.load_status["qwen"] = "‚ùå –í—ã–≥—Ä—É–∂–µ–Ω–∞"
            torch.cuda.empty_cache()
        elif model_name == "turbo" and self.turbo_model:
            del self.turbo_model
            self.turbo_model = None
            self.load_status["turbo"] = "‚ùå –í—ã–≥—Ä—É–∂–µ–Ω–∞"
            torch.cuda.empty_cache()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –º–æ–¥–µ–ª–µ–π
model_manager = ModelManager()

# –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
print("\n" + "="*50)
print("–ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô")
print("="*50)
model_manager.load_qwen_model()
asyncio.sleep(1)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–≥—Ä—É–∑–∫–∞–º–∏
model_manager.load_turbo_model()
print("="*50 + "\n")

# ==========================================
# 5. –§–£–ù–ö–¶–ò–ò –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê
# ==========================================

def get_system_stats() -> SystemStats:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Å–∏—Å—Ç–µ–º—ã"""
    ram = psutil.virtual_memory()
    
    gpu_free_mb = GPU_MEMORY_MB
    gpu_used_mb = 0
    gpu_util = 0.0
    
    if GPU_AVAILABLE:
        try:
            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
            mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
            gpu_used_mb = mem_info.used // (1024 * 1024)
            gpu_free_mb = mem_info.free // (1024 * 1024)
            
            util = pynvml.nvmlDeviceGetUtilizationRates(handle)
            gpu_util = util.gpu
        except:
            pass
    
    return SystemStats(
        gpu_memory_free_mb=gpu_free_mb,
        gpu_memory_used_mb=gpu_used_mb,
        gpu_memory_total_mb=GPU_MEMORY_MB,
        ram_free_mb=int(ram.available // (1024 * 1024)),
        ram_used_mb=int(ram.used // (1024 * 1024)),
        ram_total_mb=int(ram.total // (1024 * 1024)),
        gpu_utilization=gpu_util
    )

def check_memory_available(params: GenerationParams) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –ø–∞–º—è—Ç–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
    stats = get_system_stats()
    
    # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ (–≤ –ú–ë)
    memory_required = 200  # –ë–∞–∑–æ–≤–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ
    
    if params.model == "qwen":
        memory_required += 2000  # Qwen —Ç—Ä–µ–±—É–µ—Ç ~2GB VRAM
    elif params.model == "turbo":
        memory_required += 1500  # Turbo —Ç—Ä–µ–±—É–µ—Ç ~1.5GB VRAM
    
    memory_required += (params.width * params.height * params.batch_size) // 1024
    
    return stats.gpu_memory_free_mb > memory_required

# ==========================================
# 6. API ENDPOINTS
# ==========================================

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞"""
    return {
        "status": "üü¢ OK",
        "timestamp": datetime.now().isoformat(),
        "models": model_manager.load_status,
        "device": str(DEVICE)
    }

@app.get("/status")
async def server_status():
    """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π —Å—Ç–∞—Ç—É—Å —Å–µ—Ä–≤–µ—Ä–∞"""
    stats = get_system_stats()
    return {
        "server": "ImGen Image Generation",
        "models_loaded": {
            "qwen3-4b": model_manager.qwen_model is not None,
            "z_image_turbo": model_manager.turbo_model is not None,
        },
        "system": stats.dict(),
        "device": str(DEVICE),
        "available_models": ["qwen", "turbo"]
    }

@app.post("/generate")
async def generate_image(params: GenerationParams):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å
    if not check_memory_available(params):
        raise HTTPException(
            status_code=507,
            detail={
                "error": "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ GPU –ø–∞–º—è—Ç–∏",
                "required_mb": 2000,
                "available_mb": get_system_stats().gpu_memory_free_mb
            }
        )
    
    try:
        print(f"\nüé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ({params.model}):")
        print(f"   –ü—Ä–æ–º–ø—Ç: {params.prompt[:50]}...")
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: steps={params.num_inference_steps}, scale={params.guidance_scale}")
        
        if params.model == "turbo":
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ LCM –ø–∞–π–ø–ª–∞–π–Ω
            model = model_manager.get_model("turbo")
            
            if model is None:
                raise HTTPException(status_code=503, detail="–ú–æ–¥–µ–ª—å Stable Diffusion –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º Qwen –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
                qwen = model_manager.get_model("qwen")
                if qwen:
                    # –£–ª—É—á—à–∞–µ–º –ø—Ä–æ–º–ø—Ç —á–µ—Ä–µ–∑ Qwen
                    enhanced_prompt = qwen.create_completion(
                        prompt=f"Improve this image description: {params.prompt}",
                        max_tokens=50,
                        temperature=0.3,
                        top_p=0.9,
                    )
                    final_prompt = enhanced_prompt["choices"][0]["text"].strip()
                else:
                    final_prompt = params.prompt
            except:
                final_prompt = params.prompt
            
            print(f"   –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {final_prompt[:80]}...")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = model(
                final_prompt,
                num_inference_steps=min(params.num_inference_steps, 30),
                guidance_scale=params.guidance_scale,
                height=params.height,
                width=params.width,
                generator=torch.Generator(device="cuda" if GPU_AVAILABLE else "cpu").manual_seed(
                    params.seed if params.seed else np.random.randint(0, 1000000)
                ) if params.seed else None
            ).images[0]
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ base64
            buffered = io.BytesIO()
            image.save(buffered, format="PNG")
            img_base64 = base64.b64encode(buffered.getvalue()).decode()
            
            stats = get_system_stats()
            
            return {
                "status": "‚úÖ –£—Å–ø–µ—à–Ω–æ",
                "model": "Stable Diffusion v1.5",
                "prompt": params.prompt,
                "enhanced_prompt": final_prompt,
                "image": f"data:image/png;base64,{img_base64}",
                "generation_params": params.dict(),
                "system_stats": stats.dict(),
                "timestamp": datetime.now().isoformat()
            }
            
        elif params.model == "qwen":
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Qwen (—Ç–µ–∫—Å—Ç-—ç–Ω–∫–æ–¥–µ—Ä)
            model = model_manager.get_model("qwen")
            
            if model is None:
                raise HTTPException(status_code=503, detail="–ú–æ–¥–µ–ª—å Qwen –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            
            # Qwen –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            full_prompt = f"""–°–æ–∑–¥–∞–π –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞:
–ó–∞–ø—Ä–æ—Å: {params.prompt}

–û–ø–∏—Å–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–º, —Å –¥–µ—Ç–∞–ª—è–º–∏ –æ:
- –û–±—ä–µ–∫—Ç–∞—Ö –∏ –ø—Ä–µ–¥–º–µ—Ç–∞—Ö
- –°—Ç–∏–ª–µ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏
- –û—Å–≤–µ—â–µ–Ω–∏–∏ –∏ —Ü–≤–µ—Ç–∞—Ö
- –ö–æ–º–ø–æ–∑–∏—Ü–∏–∏ –∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–µ

–û–ø–∏—Å–∞–Ω–∏–µ (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º):"""
            
            output = model.create_completion(
                prompt=full_prompt,
                max_tokens=150,
                temperature=params.temperature,
                top_p=0.9,
                repeat_penalty=1.1,
            )
            
            enhanced_text = output["choices"][0]["text"].strip()
            
            stats = get_system_stats()
            
            return {
                "status": "‚úÖ –£—Å–ø–µ—à–Ω–æ",
                "model": "Qwen3-4B (Text Encoder)",
                "prompt": params.prompt,
                "output": enhanced_text,
                "type": "text_generation",
                "note": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç–æ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∫ –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ LCM",
                "generation_params": params.dict(),
                "system_stats": stats.dict(),
                "timestamp": datetime.now().isoformat()
            }
        else:
            raise HTTPException(status_code=400, detail=f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {params.model}")
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/generate/stream")
async def generate_image_stream(params: GenerationParams):
    """WebSocket –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –≤ –±—É–¥—É—â–µ–º
    raise HTTPException(status_code=501, detail="Streaming –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ")

@app.post("/models/unload/{model_name}")
async def unload_model(model_name: str):
    """–í—ã–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ –ø–∞–º—è—Ç–∏ –¥–ª—è –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è GPU"""
    if model_name not in ["qwen", "turbo"]:
        raise HTTPException(status_code=400, detail=f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {model_name}")
    
    model_manager.unload_model(model_name)
    torch.cuda.empty_cache()
    
    return {
        "status": "‚úÖ –ú–æ–¥–µ–ª—å –≤—ã–≥—Ä—É–∂–µ–Ω–∞",
        "model": model_name,
        "freed_memory": True,
        "system_stats": get_system_stats().dict()
    }

@app.post("/models/reload/{model_name}")
async def reload_model(model_name: str):
    """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å"""
    if model_name not in ["qwen", "turbo"]:
        raise HTTPException(status_code=400, detail=f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å: {model_name}")
    
    try:
        model_manager.unload_model(model_name)
        await asyncio.sleep(0.5)
        
        if model_name == "qwen":
            model_manager.load_qwen_model()
        else:
            model_manager.load_turbo_model()
        
        return {
            "status": "‚úÖ –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞",
            "model": model_name,
            "model_loaded": model_manager.get_model(model_name) is not None,
            "system_stats": get_system_stats().dict()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/system/memory")
async def get_memory_info():
    """–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–º—è—Ç–∏"""
    stats = get_system_stats()
    return {
        "gpu": {
            "total_mb": stats.gpu_memory_total_mb,
            "used_mb": stats.gpu_memory_used_mb,
            "free_mb": stats.gpu_memory_free_mb,
            "utilization_percent": stats.gpu_utilization,
            "available": GPU_AVAILABLE
        },
        "ram": {
            "total_mb": stats.ram_total_mb,
            "used_mb": stats.ram_used_mb,
            "free_mb": stats.ram_free_mb,
            "utilization_percent": (stats.ram_used_mb / stats.ram_total_mb * 100) if stats.ram_total_mb > 0 else 0
        }
    }

# ==========================================
# 7. –í–ï–ë-UI (HTML/CSS/JS)
# ==========================================

HTML_UI = """
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ImGen - Image Generation</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
            color: #333;
        }
        
        .container {
            max-width: 1400px;
            margin: 0 auto;
        }
        
        .header {
            text-align: center;
            color: white;
            margin-bottom: 30px;
            animation: fadeIn 0.5s ease-in;
        }
        
        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        
        .header p {
            font-size: 1.1em;
            opacity: 0.9;
        }
        
        .grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-bottom: 20px;
        }
        
        @media (max-width: 900px) {
            .grid { grid-template-columns: 1fr; }
        }
        
        .card {
            background: white;
            border-radius: 10px;
            padding: 25px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
            animation: slideUp 0.5s ease-out;
        }
        
        .card h2 {
            margin-bottom: 20px;
            color: #667eea;
            font-size: 1.5em;
            border-bottom: 2px solid #667eea;
            padding-bottom: 10px;
        }
        
        .form-group {
            margin-bottom: 15px;
        }
        
        label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            color: #333;
        }
        
        input[type="text"],
        input[type="number"],
        input[type="range"],
        select,
        textarea {
            width: 100%;
            padding: 12px;
            border: 2px solid #e0e0e0;
            border-radius: 6px;
            font-size: 1em;
            transition: border-color 0.3s;
        }
        
        input[type="text"]:focus,
        input[type="number"]:focus,
        input[type="range"]:focus,
        select:focus,
        textarea:focus {
            outline: none;
            border-color: #667eea;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
        }
        
        textarea {
            resize: vertical;
            min-height: 100px;
            font-family: inherit;
        }
        
        .slider-group {
            display: flex;
            gap: 10px;
            align-items: center;
        }
        
        input[type="range"] {
            flex: 1;
        }
        
        .slider-value {
            min-width: 60px;
            text-align: right;
            font-weight: 600;
            color: #667eea;
        }
        
        .button-group {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
            margin-top: 20px;
        }
        
        button {
            padding: 12px 20px;
            border: none;
            border-radius: 6px;
            font-size: 1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .btn-primary {
            background: #667eea;
            color: white;
            grid-column: 1 / -1;
        }
        
        .btn-primary:hover {
            background: #5568d3;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }
        
        .btn-secondary {
            background: #f0f0f0;
            color: #333;
        }
        
        .btn-secondary:hover {
            background: #e0e0e0;
        }
        
        .btn-danger {
            background: #ff6b6b;
            color: white;
        }
        
        .btn-danger:hover {
            background: #ee5a52;
        }
        
        .status-card {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 15px;
        }
        
        .stat {
            background: #f5f5f5;
            padding: 15px;
            border-radius: 6px;
            border-left: 4px solid #667eea;
        }
        
        .stat-label {
            font-size: 0.9em;
            color: #666;
            margin-bottom: 5px;
        }
        
        .stat-value {
            font-size: 1.3em;
            font-weight: 600;
            color: #333;
        }
        
        .progress-bar {
            width: 100%;
            height: 8px;
            background: #e0e0e0;
            border-radius: 4px;
            overflow: hidden;
            margin-top: 10px;
        }
        
        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea, #764ba2);
            transition: width 0.3s;
        }
        
        .message {
            padding: 15px;
            border-radius: 6px;
            margin-bottom: 15px;
            animation: slideDown 0.3s ease-out;
        }
        
        .message.success {
            background: #d4edda;
            color: #155724;
            border-left: 4px solid #28a745;
        }
        
        .message.error {
            background: #f8d7da;
            color: #721c24;
            border-left: 4px solid #f5c6cb;
        }
        
        .message.info {
            background: #d1ecf1;
            color: #0c5460;
            border-left: 4px solid #bee5eb;
        }
        
        .loading {
            display: none;
            text-align: center;
            padding: 20px;
        }
        
        .spinner {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #667eea;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 10px;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }
        
        @keyframes slideUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        @keyframes slideDown {
            from {
                opacity: 0;
                transform: translateY(-10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        .output {
            margin-top: 20px;
            padding: 15px;
            background: #f9f9f9;
            border-radius: 6px;
            max-height: 600px;
            overflow-y: auto;
            border: 1px solid #e0e0e0;
        }
        
        .output-image {
            max-width: 100%;
            max-height: 400px;
            border-radius: 6px;
            margin: 10px 0;
        }
        
        .output-title {
            font-weight: 600;
            margin-bottom: 10px;
            color: #667eea;
        }
        
        .output-text {
            white-space: pre-wrap;
            word-break: break-word;
            font-size: 0.9em;
            line-height: 1.6;
        }
        
        .tabs {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
            border-bottom: 2px solid #e0e0e0;
        }
        
        .tab {
            padding: 12px 20px;
            background: none;
            border: none;
            cursor: pointer;
            font-weight: 600;
            color: #999;
            border-bottom: 3px solid transparent;
            transition: all 0.3s;
        }
        
        .tab.active {
            color: #667eea;
            border-bottom-color: #667eea;
        }
        
        .tab-content {
            display: none;
        }
        
        .tab-content.active {
            display: block;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üé® ImGen</h1>
            <p>–°–µ—Ä–≤–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI –º–æ–¥–µ–ª–µ–π</p>
        </div>
        
        <div class="grid">
            <!-- –õ–µ–≤–∞—è –∫–æ–ª–æ–Ω–∞: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π -->
            <div class="card">
                <h2>‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏</h2>
                
                <div class="form-group">
                    <label for="model">–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏:</label>
                    <select id="model">
                        <option value="turbo">Stable Diffusion v1.5 (1.5GB, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–æ—Ç–æ)</option>
                        <option value="qwen">Qwen3-4B (2GB, —Ç–µ–∫—Å—Ç —ç–Ω–∫–æ–¥–µ—Ä)</option>
                    </select>
                </div>
                
                <div class="form-group">
                    <label for="prompt">–û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:</label>
                    <textarea id="prompt" placeholder="–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å..."></textarea>
                </div>
                
                <div class="form-group">
                    <label>–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤: <span class="slider-value" id="stepsValue">20</span></label>
                    <div class="slider-group">
                        <input type="range" id="steps" min="1" max="50" value="20">
                    </div>
                </div>
                
                <div class="form-group">
                    <label>Guidance Scale: <span class="slider-value" id="guidanceValue">7.5</span></label>
                    <div class="slider-group">
                        <input type="range" id="guidance" min="1" max="20" step="0.5" value="7.5">
                    </div>
                </div>
                
                <div class="form-group">
                    <label>–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: <span class="slider-value" id="tempValue">0.7</span></label>
                    <div class="slider-group">
                        <input type="range" id="temperature" min="0" max="2" step="0.1" value="0.7">
                    </div>
                </div>
                
                <div class="form-group">
                    <label for="width">–®–∏—Ä–∏–Ω–∞:</label>
                    <input type="number" id="width" min="256" max="1024" value="512" step="64">
                </div>
                
                <div class="form-group">
                    <label for="height">–í—ã—Å–æ—Ç–∞:</label>
                    <input type="number" id="height" min="256" max="1024" value="512" step="64">
                </div>
                
                <div class="form-group">
                    <label for="seed">Seed (–æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç–æ –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ):</label>
                    <input type="number" id="seed" placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: 42">
                </div>
                
                <div class="button-group">
                    <button class="btn-primary" onclick="generateImage()">üöÄ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å</button>
                </div>
                
                <div id="generationMessage"></div>
                <div class="loading" id="generationLoading">
                    <div class="spinner"></div>
                    <p>–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...</p>
                </div>
            </div>
            
            <!-- –ü—Ä–∞–≤–∞—è –∫–æ–ª–æ–Ω–∞: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ -->
            <div>
                <div class="card" style="margin-bottom: 20px;">
                    <h2>üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã</h2>
                    
                    <div class="tabs">
                        <button class="tab active" onclick="switchTab(event, 'gpu')">GPU</button>
                        <button class="tab" onclick="switchTab(event, 'ram')">RAM</button>
                        <button class="tab" onclick="switchTab(event, 'models')">–ú–æ–¥–µ–ª–∏</button>
                    </div>
                    
                    <div id="gpu" class="tab-content active">
                        <div class="status-card">
                            <div class="stat">
                                <div class="stat-label">–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ</div>
                                <div class="stat-value" id="gpuUsed">-</div>
                                <div class="progress-bar">
                                    <div class="progress-fill" id="gpuProgress"></div>
                                </div>
                            </div>
                            <div class="stat">
                                <div class="stat-label">–°–≤–æ–±–æ–¥–Ω–æ</div>
                                <div class="stat-value" id="gpuFree">-</div>
                            </div>
                            <div class="stat">
                                <div class="stat-label">–í—Å–µ–≥–æ</div>
                                <div class="stat-value" id="gpuTotal">-</div>
                            </div>
                            <div class="stat">
                                <div class="stat-label">–£—Ç–∏–ª–∏–∑–∞—Ü–∏—è</div>
                                <div class="stat-value" id="gpuUtil">-</div>
                            </div>
                        </div>
                    </div>
                    
                    <div id="ram" class="tab-content">
                        <div class="status-card">
                            <div class="stat">
                                <div class="stat-label">–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ</div>
                                <div class="stat-value" id="ramUsed">-</div>
                                <div class="progress-bar">
                                    <div class="progress-fill" id="ramProgress"></div>
                                </div>
                            </div>
                            <div class="stat">
                                <div class="stat-label">–°–≤–æ–±–æ–¥–Ω–æ</div>
                                <div class="stat-value" id="ramFree">-</div>
                            </div>
                            <div class="stat">
                                <div class="stat-label">–í—Å–µ–≥–æ</div>
                                <div class="stat-value" id="ramTotal">-</div>
                            </div>
                            <div class="stat">
                                <div class="stat-label">–£—Ç–∏–ª–∏–∑–∞—Ü–∏—è</div>
                                <div class="stat-value" id="ramUtil">-</div>
                            </div>
                        </div>
                    </div>
                    
                    <div id="models" class="tab-content">
                        <div style="display: flex; flex-direction: column; gap: 10px;">
                            <div id="qwenStatus" class="stat">
                                <div class="stat-label">Qwen3-4B</div>
                                <div class="stat-value">–ü—Ä–æ–≤–µ—Ä–∫–∞...</div>
                            </div>
                            <div id="turboStatus" class="stat">
                                <div class="stat-label">Stable Diffusion v1.5</div>
                                <div class="stat-value">–ü—Ä–æ–≤–µ—Ä–∫–∞...</div>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="card">
                    <h2>üîß –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª—è–º–∏</h2>
                    <button class="btn-secondary" style="width: 100%; margin-bottom: 10px;" onclick="unloadModel('qwen')">–í—ã–≥—Ä—É–∑–∏—Ç—å Qwen3-4B</button>
                    <button class="btn-secondary" style="width: 100%; margin-bottom: 10px;" onclick="reloadModel('qwen')">–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å Qwen3-4B</button>
                    <button class="btn-secondary" style="width: 100%; margin-bottom: 10px;" onclick="unloadModel('turbo')">–í—ã–≥—Ä—É–∑–∏—Ç—å Stable Diffusion</button>
                    <button class="btn-secondary" style="width: 100%;" onclick="reloadModel('turbo')">–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å Stable Diffusion</button>
                </div>
            </div>
        </div>
        
        <!-- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ -->
        <div class="card">
            <h2>üìù –†–µ–∑—É–ª—å—Ç–∞—Ç—ã</h2>
            <div id="output"></div>
        </div>
    </div>
    
    <script>
        const API_BASE = "http://localhost:8001";
        
        // –°–ª–∞–π–¥–µ—Ä—ã
        document.getElementById('steps').addEventListener('input', (e) => {
            document.getElementById('stepsValue').textContent = e.target.value;
        });
        
        document.getElementById('guidance').addEventListener('input', (e) => {
            document.getElementById('guidanceValue').textContent = e.target.value;
        });
        
        document.getElementById('temperature').addEventListener('input', (e) => {
            document.getElementById('tempValue').textContent = parseFloat(e.target.value).toFixed(1);
        });
        
        // –¢–∞–±–ª–µ—Ç–∫–∏
        function switchTab(event, tabName) {
            const tabs = document.querySelectorAll('.tab');
            const contents = document.querySelectorAll('.tab-content');
            
            tabs.forEach(tab => tab.classList.remove('active'));
            contents.forEach(content => content.classList.remove('active'));
            
            event.target.classList.add('active');
            document.getElementById(tabName).classList.add('active');
        }
        
        // –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        async function updateStats() {
            try {
                const response = await fetch(API_BASE + '/system/memory');
                const data = await response.json();
                
                // GPU
                const gpuPercent = (data.gpu.used_mb / data.gpu.total_mb * 100).toFixed(1);
                document.getElementById('gpuUsed').textContent = data.gpu.used_mb + ' MB';
                document.getElementById('gpuFree').textContent = data.gpu.free_mb + ' MB';
                document.getElementById('gpuTotal').textContent = data.gpu.total_mb + ' MB';
                document.getElementById('gpuUtil').textContent = data.gpu.utilization_percent.toFixed(1) + '%';
                document.getElementById('gpuProgress').style.width = gpuPercent + '%';
                
                // RAM
                const ramPercent = data.ram.utilization_percent.toFixed(1);
                document.getElementById('ramUsed').textContent = data.ram.used_mb + ' MB';
                document.getElementById('ramFree').textContent = data.ram.free_mb + ' MB';
                document.getElementById('ramTotal').textContent = data.ram.total_mb + ' MB';
                document.getElementById('ramUtil').textContent = ramPercent + '%';
                document.getElementById('ramProgress').style.width = ramPercent + '%';
            } catch (error) {
                console.error('–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏:', error);
            }
        }
        
        // –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π
        async function updateModelStatus() {
            try {
                const response = await fetch(API_BASE + '/health');
                const data = await response.json();
                
                const qwenLoaded = data.models.qwen.includes('‚úÖ');
                const turboLoaded = data.models.turbo.includes('‚úÖ');
                
                document.getElementById('qwenStatus').innerHTML = `
                    <div class="stat-label">Qwen3-4B</div>
                    <div class="stat-value">${qwenLoaded ? '‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞' : '‚ùå –ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}</div>
                `;
                
                document.getElementById('turboStatus').innerHTML = `
                    <div class="stat-label">z_image_turbo</div>
                    <div class="stat-value">${turboLoaded ? '‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞' : '‚ùå –ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞'}</div>
                `;
            } catch (error) {
                console.error('–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–µ–ª–µ–π:', error);
            }
        }
        
        // –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        async function generateImage() {
            const prompt = document.getElementById('prompt').value;
            if (!prompt.trim()) {
                showMessage('–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ', 'error');
                return;
            }
            
            const params = {
                prompt: prompt,
                model: document.getElementById('model').value,
                num_inference_steps: parseInt(document.getElementById('steps').value),
                guidance_scale: parseFloat(document.getElementById('guidance').value),
                temperature: parseFloat(document.getElementById('temperature').value),
                width: parseInt(document.getElementById('width').value),
                height: parseInt(document.getElementById('height').value),
                seed: document.getElementById('seed').value ? parseInt(document.getElementById('seed').value) : null,
                batch_size: 1
            };
            
            document.getElementById('generationLoading').style.display = 'block';
            document.getElementById('generationMessage').innerHTML = '';
            
            try {
                const response = await fetch(API_BASE + '/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(params)
                });
                
                const result = await response.json();
                
                if (response.ok) {
                    showMessage('‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!', 'success');
                    displayOutput(result);
                } else {
                    showMessage(`‚ùå –û—à–∏–±–∫–∞: ${result.detail}`, 'error');
                }
            } catch (error) {
                showMessage(`‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: ${error.message}`, 'error');
            } finally {
                document.getElementById('generationLoading').style.display = 'none';
            }
        }
        
        // –í—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
        async function unloadModel(modelName) {
            try {
                const response = await fetch(API_BASE + `/models/unload/${modelName}`, {
                    method: 'POST'
                });
                const result = await response.json();
                
                if (response.ok) {
                    showMessage(`‚úÖ ${modelName} –≤—ã–≥—Ä—É–∂–µ–Ω–∞`, 'success');
                    updateModelStatus();
                } else {
                    showMessage(`‚ùå –û—à–∏–±–∫–∞: ${result.detail}`, 'error');
                }
            } catch (error) {
                showMessage(`‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: ${error.message}`, 'error');
            }
        }
        
        // –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
        async function reloadModel(modelName) {
            try {
                const response = await fetch(API_BASE + `/models/reload/${modelName}`, {
                    method: 'POST'
                });
                const result = await response.json();
                
                if (response.ok) {
                    showMessage(`‚úÖ ${modelName} –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω–∞`, 'success');
                    updateModelStatus();
                } else {
                    showMessage(`‚ùå –û—à–∏–±–∫–∞: ${result.detail}`, 'error');
                }
            } catch (error) {
                showMessage(`‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏: ${error.message}`, 'error');
            }
        }
        
        // –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        function showMessage(text, type) {
            const messageDiv = document.getElementById('generationMessage');
            messageDiv.innerHTML = `<div class="message ${type}">${text}</div>`;
        }
        
        function displayOutput(result) {
            const output = document.getElementById('output');
            let resultHtml = `
                <div class="output">
                    <div class="output-title">üìå –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:</div>
                    <div class="output-text">
                        –ú–æ–¥–µ–ª—å: ${result.model}
                        –ü—Ä–æ–º–ø—Ç: ${result.prompt}
                        –®–∞–≥–∏: ${result.generation_params.num_inference_steps}
                        Guidance Scale: ${result.generation_params.guidance_scale}
                        –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ: ${result.generation_params.width}x${result.generation_params.height}
                    </div>
            `;
            
            // –ï—Å–ª–∏ –µ—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º –µ–≥–æ
            if (result.image) {
                resultHtml += `
                    <div class="output-title">üñºÔ∏è –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:</div>
                    <img src="${result.image}" class="output-image" alt="Generated image">
                `;
            }
            
            // –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if (result.output) {
                resultHtml += `
                    <div class="output-title">üìù –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:</div>
                    <div class="output-text">${result.output}</div>
                `;
            }
            
            // –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            resultHtml += `
                    <div class="output-title">üíæ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:</div>
                    <div class="output-text">
                        GPU: ${result.system_stats.gpu_memory_used_mb}/${result.system_stats.gpu_memory_total_mb} MB
                        RAM: ${result.system_stats.ram_used_mb}/${result.system_stats.ram_total_mb} MB
                        GPU Util: ${result.system_stats.gpu_utilization.toFixed(1)}%
                    </div>
                </div>
            `;
            
            output.innerHTML = resultHtml;
        }
        
        // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        window.addEventListener('load', () => {
            updateStats();
            updateModelStatus();
            setInterval(updateStats, 2000);
            setInterval(updateModelStatus, 5000);
        });
    </script>
</body>
</html>
"""

@app.get("/")
async def root():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º"""
    return {
        "message": "ImGen Server",
        "info": "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /ui –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –∏–ª–∏ /docs –¥–ª—è API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"
    }

@app.get("/ui")
async def get_ui():
    from fastapi.responses import HTMLResponse
    return HTMLResponse(content=HTML_UI)

# ==========================================
# 8. –ó–ê–ü–£–°–ö –°–ï–†–í–ï–†–ê
# ==========================================

if __name__ == "__main__":
    print("\n" + "="*60)
    print("üöÄ ImGen Server –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    print("="*60)
    print(f"üìç –í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å: http://localhost:8001/ui")
    print(f"üìö API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8001/docs")
    print(f"üè• –ó–¥–æ—Ä–æ–≤—å–µ —Å–µ—Ä–≤–µ—Ä–∞: http://localhost:8001/health")
    print("="*60 + "\n")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8001,
        log_level="info"
    )
